<img width="260" height="260" alt="image" src="https://github.com/user-attachments/assets/3e53cc7e-0a0f-4373-bed2-d31e5e495f06" />



# Task 1: Chatbot with Memory

## Objective:
Build a conversational chatbot that retains context across interactions.

## Tools Used : LLM: Gemini Pro via Google AI Studio API
Framework: LangChain (Python)
Memory: ConversationBufferMemory or ConversationSummaryBufferMemory

## Explanation : 

1. First i store collected Api in colab Secrets
2. then i define my llm
3. i define a ConversationSummaryBufferMemory
4. then i include my llm in memory to make my model memory present
5. finally i use gradio in order to visualise my chatbox


## Deployement : 

Finally i deplloyed my app on streamlit 
App link : https://finwise-genai-assistant-puf9qq6dprr9aqtkchgfcm.streamlit.app/

<img width="1903" height="847" alt="image" src="https://github.com/user-attachments/assets/ba75a161-9c49-4514-96f9-3b8df3973d99" />


